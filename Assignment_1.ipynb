{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPvnN2mGAmZw25dwbAiYx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranav335/CS910/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "CG42l1nIHI4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "H1isRrCCHEs6"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "I17ul_OhHTub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(xtrain, ytrain), (xtest, ytest) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "hz8t9YslHTBP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PVSj8Q9HvE5",
        "outputId": "8e3b60d9-5cbf-4b75-cf05-553aa033d217"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcJSsnR_HxVT",
        "outputId": "f3f51ade-a7b2-42df-c838-1a50016a73c7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(xtrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8AImJmxHzat",
        "outputId": "2b9862d5-8858-403b-bcec-14974932a337"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.imshow(xtrain[2,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GMGpdKYiH2zm",
        "outputId": "989a6799-e395-4999-d763-eb7da70e6c72"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb0fc6eb190>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  exps = np.exp(x)\n",
        "  return exps/ np.sum(exps, axis = -1, keepdims = True)\n",
        "\n",
        "x = np.array([[1, 2], [4 ,2], [3,2]])\n",
        "softmax(x=x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMM06ZAxzOB0",
        "outputId": "8c9d8270-ceb3-4476-842d-0b3147650b90"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.26894142, 0.73105858],\n",
              "       [0.88079708, 0.11920292],\n",
              "       [0.73105858, 0.26894142]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(np.exp(x), axis = -1, keepdims = True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5-uaei_0cS8",
        "outputId": "44a3e801-fa46-4a85-eb30-d92d073f5386"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkVTWRNq0caW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2\n",
        "\n",
        "\n",
        "Lets define the dimension of the various matrixes and vector.\n",
        "\n",
        "W -> (N)"
      ],
      "metadata": {
        "id": "OBCa81n4IPvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class neural_network:\n",
        "\n",
        "  def __init__(self, x , hidden_layer = [2]):\n",
        "    self.x = x\n",
        "    self.n_x = x.shape[1]\n",
        "    self.L = len(hidden_layer)\n",
        "    self.neuron = [self.n_x] + hidden_layer + [10]\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    for i in range(self.L + 1):\n",
        "      self.W[i+1] = np.random.randn(self.neuron[i], self.neuron[i+1])\n",
        "      self.B[i+1] = np.zeros((self.neuron[i+1]))\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps/ np.sum(exps, axis = -1, keepdims = True)\n",
        "\n",
        "  def forward_pass(self):\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    self.H[0] = self.x\n",
        "    for i in range(self.L):\n",
        "      self.A[i+1] = self.H[i] @ self.W[i+1] + self.B[i+1]\n",
        "      self.H[i+1] = self.sigmoid(self.A[i+1])\n",
        "\n",
        "    self.A[self.L+1] = self.H[self.L] @ self.W[self.L+1] + self.B[self.L+1]\n",
        "    self.H[self.L+1] = self.softmax(self.A[self.L + 1])\n",
        "\n",
        "    return self.H[self.L+1]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MXiq2fABIRVY"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the array into a new row.\n",
        "xtrain = np.reshape(xtrain, (xtrain.shape[0], -1))/255\n",
        "xtest = np.reshape(xtrain, (xtest.shape[0], -1))/255\n",
        "xtrain.shape"
      ],
      "metadata": {
        "id": "CpFpECmXIDNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c54cba-7f80-4310-ed2f-14099347ee69"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain[1, :]"
      ],
      "metadata": {
        "id": "UD9YzEmNwRIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e114d4-f042-4b8d-fd07-4c2a3d6448a0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.16078431, 0.7372549 , 0.40392157, 0.21176471, 0.18823529,\n",
              "       0.16862745, 0.34117647, 0.65882353, 0.52156863, 0.0627451 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.19215686, 0.53333333, 0.85882353, 0.84705882, 0.89411765,\n",
              "       0.9254902 , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.85098039, 0.84313725, 0.99607843, 0.90588235, 0.62745098,\n",
              "       0.17647059, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.05490196, 0.69019608, 0.87058824, 0.87843137,\n",
              "       0.83137255, 0.79607843, 0.77647059, 0.76862745, 0.78431373,\n",
              "       0.84313725, 0.8       , 0.79215686, 0.78823529, 0.78823529,\n",
              "       0.78823529, 0.81960784, 0.85490196, 0.87843137, 0.64313725,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.7372549 ,\n",
              "       0.85882353, 0.78431373, 0.77647059, 0.79215686, 0.77647059,\n",
              "       0.78039216, 0.78039216, 0.78823529, 0.76862745, 0.77647059,\n",
              "       0.77647059, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
              "       0.78823529, 0.78431373, 0.88235294, 0.16078431, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.2       , 0.85882353, 0.78039216, 0.79607843,\n",
              "       0.79607843, 0.83137255, 0.93333333, 0.97254902, 0.98039216,\n",
              "       0.96078431, 0.97647059, 0.96470588, 0.96862745, 0.98823529,\n",
              "       0.97254902, 0.92156863, 0.81176471, 0.79607843, 0.79607843,\n",
              "       0.87058824, 0.54901961, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
              "       0.88627451, 0.80784314, 0.8       , 0.81176471, 0.8       ,\n",
              "       0.39607843, 0.29411765, 0.18431373, 0.28627451, 0.18823529,\n",
              "       0.19607843, 0.17647059, 0.2       , 0.24705882, 0.44313725,\n",
              "       0.87058824, 0.79215686, 0.80784314, 0.8627451 , 0.87843137,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.78431373, 0.87058824, 0.81960784,\n",
              "       0.79607843, 0.84313725, 0.78431373, 0.        , 0.2745098 ,\n",
              "       0.38431373, 0.        , 0.40392157, 0.23137255, 0.26666667,\n",
              "       0.27843137, 0.19215686, 0.        , 0.85882353, 0.80784314,\n",
              "       0.83921569, 0.82352941, 0.98039216, 0.14901961, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.96862745, 0.85490196, 0.83137255, 0.82352941, 0.84313725,\n",
              "       0.83921569, 0.        , 0.99607843, 0.95294118, 0.54509804,\n",
              "       1.        , 0.68235294, 0.98431373, 1.        , 0.80392157,\n",
              "       0.        , 0.84313725, 0.85098039, 0.83921569, 0.81568627,\n",
              "       0.8627451 , 0.37254902, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.17647059, 0.88627451, 0.83921569,\n",
              "       0.83921569, 0.84313725, 0.87843137, 0.80392157, 0.        ,\n",
              "       0.16470588, 0.1372549 , 0.23529412, 0.0627451 , 0.06666667,\n",
              "       0.04705882, 0.05098039, 0.2745098 , 0.        , 0.74117647,\n",
              "       0.84705882, 0.83137255, 0.80784314, 0.83137255, 0.61176471,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.64313725, 0.92156863, 0.83921569, 0.82745098, 0.8627451 ,\n",
              "       0.84705882, 0.78823529, 0.20392157, 0.27843137, 0.34901961,\n",
              "       0.36862745, 0.3254902 , 0.30588235, 0.2745098 , 0.29803922,\n",
              "       0.36078431, 0.34117647, 0.80784314, 0.81176471, 0.87058824,\n",
              "       0.83529412, 0.85882353, 0.81568627, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.41568627, 0.73333333,\n",
              "       0.8745098 , 0.92941176, 0.97254902, 0.82745098, 0.77647059,\n",
              "       0.98823529, 0.98039216, 0.97254902, 0.96078431, 0.97254902,\n",
              "       0.98823529, 0.99215686, 0.98039216, 0.98823529, 0.9372549 ,\n",
              "       0.78823529, 0.83137255, 0.88235294, 0.84313725, 0.75686275,\n",
              "       0.44313725, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.06666667, 0.21176471,\n",
              "       0.62352941, 0.87058824, 0.75686275, 0.81568627, 0.75294118,\n",
              "       0.77254902, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
              "       0.78823529, 0.79607843, 0.76470588, 0.82352941, 0.64705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18431373, 0.88235294,\n",
              "       0.75294118, 0.83921569, 0.79607843, 0.80784314, 0.8       ,\n",
              "       0.8       , 0.80392157, 0.80784314, 0.8       , 0.83137255,\n",
              "       0.77254902, 0.85490196, 0.41960784, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00392157, 0.02352941,\n",
              "       0.        , 0.18039216, 0.83137255, 0.76470588, 0.83137255,\n",
              "       0.79215686, 0.80784314, 0.80392157, 0.8       , 0.80392157,\n",
              "       0.80784314, 0.8       , 0.83137255, 0.78431373, 0.85490196,\n",
              "       0.35686275, 0.        , 0.01176471, 0.00392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.04313725,\n",
              "       0.77254902, 0.78039216, 0.80392157, 0.79215686, 0.80392157,\n",
              "       0.80784314, 0.8       , 0.80392157, 0.81176471, 0.8       ,\n",
              "       0.80392157, 0.80392157, 0.85490196, 0.30196078, 0.        ,\n",
              "       0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.01176471, 0.        , 0.00784314, 0.74901961, 0.77647059,\n",
              "       0.78823529, 0.80392157, 0.80784314, 0.80392157, 0.80392157,\n",
              "       0.80784314, 0.81960784, 0.80784314, 0.78039216, 0.81960784,\n",
              "       0.85882353, 0.29019608, 0.        , 0.01960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
              "       0.        , 0.7372549 , 0.77254902, 0.78431373, 0.81176471,\n",
              "       0.81176471, 0.8       , 0.81176471, 0.81176471, 0.82352941,\n",
              "       0.81568627, 0.77647059, 0.81176471, 0.86666667, 0.28235294,\n",
              "       0.        , 0.01568627, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00784314, 0.        , 0.        , 0.84313725,\n",
              "       0.77647059, 0.79607843, 0.80784314, 0.81568627, 0.80392157,\n",
              "       0.81176471, 0.81176471, 0.82352941, 0.81568627, 0.78431373,\n",
              "       0.79215686, 0.87058824, 0.29411765, 0.        , 0.01568627,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.        , 0.        , 0.83137255, 0.77647059, 0.81960784,\n",
              "       0.80784314, 0.81960784, 0.80784314, 0.81568627, 0.81176471,\n",
              "       0.82745098, 0.80784314, 0.80392157, 0.77647059, 0.86666667,\n",
              "       0.31372549, 0.        , 0.01176471, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "       0.8       , 0.78823529, 0.80392157, 0.81568627, 0.81176471,\n",
              "       0.80392157, 0.82745098, 0.80392157, 0.82352941, 0.82352941,\n",
              "       0.81960784, 0.76470588, 0.86666667, 0.37647059, 0.        ,\n",
              "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.00392157, 0.        , 0.        , 0.79215686, 0.78823529,\n",
              "       0.80392157, 0.81960784, 0.81176471, 0.80392157, 0.83529412,\n",
              "       0.80784314, 0.82352941, 0.81960784, 0.82352941, 0.76078431,\n",
              "       0.85098039, 0.41176471, 0.        , 0.00784314, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
              "       0.        , 0.8       , 0.8       , 0.80392157, 0.81568627,\n",
              "       0.81176471, 0.80392157, 0.84313725, 0.81176471, 0.82352941,\n",
              "       0.81568627, 0.82745098, 0.75686275, 0.83529412, 0.45098039,\n",
              "       0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.8       ,\n",
              "       0.81176471, 0.81176471, 0.81568627, 0.80784314, 0.80784314,\n",
              "       0.84313725, 0.82352941, 0.82352941, 0.81176471, 0.83137255,\n",
              "       0.76470588, 0.82352941, 0.4627451 , 0.        , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "       0.        , 0.        , 0.77647059, 0.81568627, 0.81568627,\n",
              "       0.81568627, 0.8       , 0.81176471, 0.83137255, 0.83137255,\n",
              "       0.82352941, 0.81176471, 0.82745098, 0.76862745, 0.81176471,\n",
              "       0.4745098 , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "       0.77647059, 0.82352941, 0.81176471, 0.81568627, 0.80784314,\n",
              "       0.81960784, 0.83529412, 0.83137255, 0.82745098, 0.81176471,\n",
              "       0.82352941, 0.77254902, 0.81176471, 0.48627451, 0.        ,\n",
              "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.6745098 , 0.82352941,\n",
              "       0.79607843, 0.78823529, 0.78039216, 0.8       , 0.81176471,\n",
              "       0.80392157, 0.8       , 0.78823529, 0.80392157, 0.77254902,\n",
              "       0.80784314, 0.49803922, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.7372549 , 0.86666667, 0.83921569, 0.91764706,\n",
              "       0.9254902 , 0.93333333, 0.95686275, 0.95686275, 0.95686275,\n",
              "       0.94117647, 0.95294118, 0.83921569, 0.87843137, 0.63529412,\n",
              "       0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00392157, 0.        , 0.        , 0.54509804,\n",
              "       0.57254902, 0.50980392, 0.52941176, 0.52941176, 0.5372549 ,\n",
              "       0.49019608, 0.48627451, 0.49019608, 0.4745098 , 0.46666667,\n",
              "       0.44705882, 0.50980392, 0.29803922, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "OzohHvy-38EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "import matplotlib.pyplot as plt\n",
        "class neural_network:\n",
        "\n",
        "  def __init__(self, x , hidden_layer = [2]):\n",
        "    self.x = x # (N x 784)\n",
        "    self.n_x = x.shape[1] # 784\n",
        "    self.L = len(hidden_layer) # 1\n",
        "    self.neuron = [self.n_x] + hidden_layer + [10] # [784, 1, 10 ]\n",
        "    self.W = {}\n",
        "    self.B = {}\n",
        "    self.A = {}\n",
        "    self.H = {}\n",
        "    for i in range(self.L + 1):\n",
        "      self.W[i+1] = np.random.randn(self.neuron[i+1], self.neuron[i]) #[n_y x n_x]\n",
        "      self.B[i+1] = np.zeros((self.neuron[i+1], 1)) # [n_y, 1]\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "  def softmax(self, x):\n",
        "    exps = np.exp(x)\n",
        "    return exps/ np.sum(exps, axis = -1, keepdims = True)\n",
        "\n",
        "  def forward_pass(self):\n",
        "    self.H[0] = self.x.T # (784 x N)\n",
        "    for i in range(self.L):\n",
        "      self.A[i+1] = self.W[i+1] @ self.H[i]  + self.B[i+1] # (2, 784) x (784, N) + (2, 1) -> (2, N)\n",
        "      self.H[i+1] = self.sigmoid(self.A[i+1]) #(2, N)\n",
        "\n",
        "    self.A[self.L+1] = self.W[self.L+1] @ self.H[self.L] + self.B[self.L+1] #(k, k-1) x (k-1, N) + (k, 1)-> (k, N)\n",
        "    self.H[self.L+1] = self.softmax(self.A[self.L + 1]) # (k, N)\n",
        "\n",
        "    return self.H[self.L+1] \n",
        "\n",
        "  def grad_sigmoid(self,x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "  def gradient(self, y):\n",
        "    self.dW = {}\n",
        "    self.dB = {}\n",
        "    self.dA = {}\n",
        "    self.dH = {}\n",
        "    # y = (N, k)\n",
        "    self.forward_pass()\n",
        "    self.dA[self.L + 1] = self.H[self.L+1] - y.T # (k, N)\n",
        "    for k in range(self.L+1, 0, -1):\n",
        "      self.dW[k] = self.dA[k] @ self.H[k-1].T # (2, N) x (N, 2) -> (2, 2)\n",
        "      self.dB[k] = np.sum(self.dA[k], axis = 1).reshape(-1, 1) # (2, N) -> (2, 1)\n",
        "      if k > 1:\n",
        "        self.dH[k-1] = self.W[k].T @ self.dA[k] \n",
        "        self.dA[k-1] = self.dH[k-1] * self.grad_sigmoid(self.A[k-1])\n",
        "\n",
        "  def fit_neural_network(self,Y, epochs = 1000, lr = 0.1):\n",
        "    loss = []\n",
        "    for i in range(epochs):\n",
        "      self.gradient(Y) # Y -> (N, k)\n",
        "\n",
        "      for i in range(self.L + 1):\n",
        "        self.W[i+1] -= lr * self.dW[i+1]\n",
        "        self.B[i+1] -= lr * self.dB[i+1]\n",
        "      \n",
        "      yhat = self.forward_pass()\n",
        "      epoch_loss = log_loss(Y,yhat.T)\n",
        "      loss.append(epoch_loss)\n",
        "\n",
        "    \n",
        "    plt.plot([*range(epochs)], loss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D888uSgs4Lap"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHXxsYamfe4p",
        "outputId": "4f2ab068-d279-488b-bab4-8c452e9e1a30"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "ytrain_oh = encoder.fit_transform(ytrain.reshape(-1,1))\n",
        "ytest_oh = encoder.fit_transform(ytest.reshape(-1,1))"
      ],
      "metadata": {
        "id": "DvZ_woArfgNs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_oh = ytrain_oh.toarray()\n",
        "ytest_oh = ytest_oh.toarray()"
      ],
      "metadata": {
        "id": "Q9OCEqx6idzW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_oh.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C3hqHuFisEJ",
        "outputId": "d7ce02af-e17b-4d32-9e7a-244e069dd515"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn = neural_network(xtrain[:100, :])\n",
        "yhat = nn.forward_pass()\n",
        "yhat.shape\n",
        "nn.fit_neural_network(ytrain_oh[:100, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-OJTLr9el00",
        "outputId": "f55c4b8f-6eb6-4c20-d542-3f66aedf189d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return 1.0/(1.0 + np.exp(-x))\n",
            "<ipython-input-69-3baabae3a753>:37: RuntimeWarning: overflow encountered in multiply\n",
            "  return x * (1 - x)\n",
            "<ipython-input-69-3baabae3a753>:48: RuntimeWarning: invalid value encountered in matmul\n",
            "  self.dW[k] = self.dA[k] @ self.H[k-1].T # (2, N) x (N, 2) -> (2, 2)\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-29964d5e5bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain_oh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-3baabae3a753>\u001b[0m in \u001b[0;36mfit_neural_network\u001b[0;34m(self, Y, epochs, lr)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2377\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;36m209.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \"\"\"\n\u001b[0;32m-> 2379\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.W.keys(), nn.A.keys(), nn.H.keys()\n",
        "nn.dW.keys(), nn.dA.keys(), nn.H.keys()"
      ],
      "metadata": {
        "id": "htFf9drajteQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[*range(1+1, 0, -1)]"
      ],
      "metadata": {
        "id": "pmf9mwr5e7pd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}